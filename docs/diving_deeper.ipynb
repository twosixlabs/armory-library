{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diving Deeper: Alternatives for importing models\n",
    "\n",
    "In [Getting Started][colab-getting-started], we imported a model from Hugging Face. Here, we will demonstrate what it looks like to import models from [GitHub][github], [PyPI][pypi], and jatic_toolbox.\n",
    "\n",
    "[colab-getting-started]: https://colab.research.google.com/github/twosixlabs/armory-library/blob/master/docs/getting_started.ipynb\n",
    "\n",
    "[pypi]: https://pypi.org\n",
    "[github]: https://github.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GitHub\n",
    "\n",
    "The following is an example of how to import a model from GitHub, after having\n",
    "cloned the relevant repository:\n",
    "```\n",
    "git clone 'https://github.com/Lornatang/SRGAN-PyTorch'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import sys\n",
    "sys.path.insert(0,'/SRGAN-PyTorch')\n",
    "from SRGAN-PyTorch import model as pytorch_new_model\n",
    "\n",
    "SRRmodel = pytorch_new_model.SRResNet()\n",
    "\n",
    "model = JaticImageClassificationModel(\n",
    "    SRRmodel\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we add the GitHub folder to the system path and import the mode. Then,\n",
    "`JaticImageClassificationModel` is a wrapper to make the model compatible with\n",
    "Armory.\n",
    "\n",
    "#### PyPI\n",
    "\n",
    "The following is an example of loading a model from the [EfficientNet Lite][eff-lite]\n",
    "PyTorch library:\n",
    "\n",
    "[eff-lite]: https://pypi.org/project/efficientnet-lite-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet_lite_pytorch import EfficientNet\n",
    "from efficientnet_lite0_pytorch_model import EfficientnetLite0ModelFile\n",
    "\n",
    "from charmory.model.image_classification import JaticImageClassificationModel\n",
    "\n",
    "weights_path = EfficientnetLite0ModelFile.get_model_file_path()\n",
    "\n",
    "lite0_model = EfficientNet.from_pretrained('efficientnet-lite0', weights_path = weights_path )\n",
    "\n",
    "model = JaticImageClassificationModel(\n",
    "    lite0_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we import the library and create a model from the case with a weights path\n",
    "added.\n",
    "\n",
    "#### jatic_toolbox\n",
    "\n",
    "The following is an example of loading a [TorchVision][torchvision] model from the jatic_toolbox:\n",
    "\n",
    "[torchvision]: https://pytorch.org/vision/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jatic_toolbox import load_model\n",
    "\n",
    "from charmory.track import track_params\n",
    "\n",
    "model = track_params(load_model)(\n",
    "        provider=\"torchvision\",\n",
    "        model_name=\"resnet34\",\n",
    "        task=\"image-classification\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`load_model` takes the self-explanatory parameters `provider`, `model_name`, and `task`, and in this case, we choose an image classification model named [resnet34][resnet34]. It can be accessed directly via the PyTorch Hub without having TorchVision installed.\n",
    "\n",
    "In each case, we use the `PyTorchClassifier` wrapper to make the model\n",
    "compatible with the ART library. Note that this is specific to image\n",
    "classification models written within the PyTorch framework. The parameters can\n",
    "be adjusted as needed and are more thoroughly described in [Getting Started][colab-getting-started]. `track_initial_params` is used so that these parameters\n",
    "are also tracked in MLflow.\n",
    "\n",
    "[resnet34]: https://pytorch.org/vision/main/models/generated/torchvision.models.resnet34.html\n",
    "[colab-getting-started]: https://colab.research.google.com/github/twosixlabs/armory-library/blob/master/docs/getting_started.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "from charmory.track import track_init_params\n",
    "import torch\n",
    "\n",
    "classifier = track_init_params(PyTorchClassifier)(\n",
    "    model,\n",
    "    loss=torch.nn.CrossEntropyLoss(),\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=0.003),\n",
    "    input_shape=(3, 224, 224),\n",
    "    channels_first=True,\n",
    "    nb_classes=10,\n",
    "    clip_values=(-1, 1),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
