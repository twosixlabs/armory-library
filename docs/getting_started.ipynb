{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite concepts in an Armory context\n",
    "\n",
    "### Dataset\n",
    "\n",
    "A dataset is a collection of images (samples) in a sequence-like structure such as a\n",
    "tuple, map, or numpy array. Each can have a target (label) assigned. Datasets can be\n",
    "imported from a variety of sources such as [PyTorch][pytorch], [Hugging Face][huggingface], or [GitHub][github].\n",
    "\n",
    "[pytorch]: https://pytorch.org\n",
    "[huggingface]: https://huggingface.co\n",
    "[github]: https://github.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic\n",
    "\n",
    "The following is a basic example of loading tuple data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from charmory.data import TupleDataset\n",
    "\n",
    "raw_dataset = [\n",
    "        ([1, 2, 3], 4),\n",
    "        ([5, 6, 7], 8),\n",
    "    ]\n",
    "\n",
    "keyed_dataset = TupleDataset(raw_dataset, x_key=\"data\", y_key=\"target\")\n",
    "\n",
    "keyed_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see that we have turned the raw dataset into a map with keys \"data\" and\n",
    "\"target\". These keys are arbitrary; the same ones just need to be provided in\n",
    "the evaluation later and correspond to the images and labels respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hugging Face\n",
    "\n",
    "The following is an example of how to load a dataset from [Hugging Face][huggingface]:\n",
    "\n",
    "[huggingface]: https://huggingface.co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import datasets # Hugging Face dataset library\n",
    "\n",
    "from charmory.data import ArmoryDataLoader\n",
    "from transformers import AutoImageProcessor # Hugging Face image processor class\n",
    "\n",
    "dataset = datasets.load_dataset(\"mnist\", split=\"test\")\n",
    "processor = AutoImageProcessor.from_pretrained(\n",
    "        \"farleyknight-org-username/vit-base-mnist\"  # Hugging Face model card\n",
    "    )\n",
    "\n",
    "def transform(processor, sample):\n",
    "    # Use the HF image processor and convert from BW To RGB\n",
    "    sample[\"image\"] = processor([img.convert(\"RGB\") for img in sample[\"image\"]])[\n",
    "        \"pixel_values\"\n",
    "    ]\n",
    "    return sample\n",
    "\n",
    "dataset.set_transform(functools.partial(transform, processor))\n",
    "dataloader = ArmoryDataLoader(dataset, batch_size=16, num_workers=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_dataset` functions imports the [MNIST][mnist] (handwritten digit)\n",
    "dataset from Hugging Face. The `split` parameter specifies which subset of the\n",
    "dataset to load, is usually either `train` or `test` or possibly `validation`,\n",
    "depending on the dataset.\n",
    "\n",
    "The `processor` is needed to ensure the dataset is pre-processed into a form\n",
    "that can be inputted into the model. The path passed into this function is a\n",
    "Hugging Face model card location, but just the preprocessor is pulled in.\n",
    "\n",
    "`AutoImageProcessor.from_pretrained` expects a Hugging Face name for the model\n",
    "card. We use the [vit-base-mnist][mnist_model] model which corresponds to the dataset.\n",
    "\n",
    "The function `transform` then cycles through the dataset and converts each image\n",
    "into Hugging Face's 'RGB' form. The `set_transform` method is used the the\n",
    "Hugging Face dataset and applied the transform function to the entire Hugging\n",
    "Face dataset.\n",
    "\n",
    "Then the PyTorch `ArmoryDataLoader` generates the numpy arrays that are\n",
    "required by ART for the evaluation. `batch_size` and `num_workers` can be set per the system and user's needs and requirements.\n",
    "\n",
    "[mnist]: https://huggingface.co/datasets/mnist\n",
    "[mnist_model]: https://huggingface.co/farleyknight-org-username/vit-base-mnist\n",
    "\n",
    "### Model\n",
    "\n",
    "A model is the output of a machine learning algorithm run on a training set of\n",
    "data. It is used to identify patterns or make predictions on unseen datasets.\n",
    "Models can be imported from a variety of sources, including [Hugging Face][huggingface],\n",
    "[GitHub][github], [PyPI][pypi], and jatic_toolbox.\n",
    "\n",
    "[pypi]: https://pypi.org\n",
    "[huggingface]: https://huggingface.co\n",
    "[github]: https://github.com\n",
    "\n",
    "\n",
    "#### Hugging Face\n",
    "\n",
    "The following is an example of how to import a model from [Hugging Face][huggingface]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "from charmory.model.image_classification import JaticImageClassificationModel\n",
    "from charmory.track import track_params\n",
    "\n",
    "model = JaticImageClassificationModel(\n",
    "        track_params(AutoModelForImageClassification.from_pretrained)(\n",
    "            \"farleyknight-org-username/vit-base-mnist\"\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `farleyknight-org-username/vit-base-mnist` is the Hugging Face model card\n",
    "name. This model was trained on the same mnist dataset as we used above.\n",
    "`track_params` is a function wrapper that stores the argument values as\n",
    "parameters in MLflow and `JaticImageClassificationModel` is a wrapper to make\n",
    "the model compatible with Armory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jatic_toolbox import load_model \n",
    "\n",
    "model = track_params(load_model)(\n",
    "        provider=\"torchvision\",\n",
    "        model_name=\"resnet34\",\n",
    "        task=\"image-classification\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the [`PyTorchClassifier`][pytorchclassifier] wrapper to make the model compatible with\n",
    "the ART library. Note that this is specific to image classification models\n",
    "written within the PyTorch framework. The parameters can be adjusted as needed. Here, we have `loss` being set to [`CrossEntropyLoss`][cel] from PyTorch's `nn` (neural network) class. This criterion computers the cross entropy loss between input logits and the target. The `optimizer` chosen is [`Adam`][adam] from PyTorch's `optim` (optimizer algorithms) class. It has its own set of parameters, to include `lr` which is the learning rate. The `input_shape` is simply the size of the input. `channels_first` specifies whether channels should be set first or last. In this case, True means they'll be set first. `nb_classes` is the number of prediction classes - in our case, 10. And finally, `clip_values` is the tuple form (min, max) of floats or np.ndarray representing the min/max values allowed for features. Since we're using single float values, these will be the range of all features.\n",
    "\n",
    "`track_initial_params` is used so that these parameters are also tracked in\n",
    "MLflow.\n",
    "\n",
    "[pytorchclassifier]: https://adversarial-robustness-toolbox.readthedocs.io/en/latest/modules/estimators/classification.html#pytorch-classifier\n",
    "[cel]: https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss\n",
    "[adam]: https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "from charmory.track import track_init_params\n",
    "import torch\n",
    "\n",
    "classifier = track_init_params(PyTorchClassifier)(\n",
    "    model,\n",
    "    loss=torch.nn.CrossEntropyLoss(),\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=0.003),\n",
    "    input_shape=(3, 224, 224),\n",
    "    channels_first=True,\n",
    "    nb_classes=10,\n",
    "    clip_values=(-1, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other\n",
    "\n",
    "To see examples of importing models from other places such as GitHub and PyPI,\n",
    "please see the auxiliary notebook, [Diving Deeper][colab-diving-deeper].\n",
    "\n",
    "[colab-diving-deeper]: https://colab.research.google.com/github/twosixlabs/armory-library/blob/master/docs/diving_deeper.ipynb\n",
    "\n",
    "### Attack\n",
    "\n",
    "An attack is a transformation of (each sample in) the dataset in order to\n",
    "disrupt the machine learning algorithm's results. For example, after an attack,\n",
    "the model may misclassify an image or fail to detect an object. In Armory,\n",
    "targeted attacks are designed to focus on only one class at a time. This is how\n",
    "we test the adversarial robustness of a machine learning model.\n",
    "\n",
    "Attacks can be loaded from [IBM's Adversarial Robustness Toolbox][art].\n",
    "\n",
    "The following is an example of how to define an attack from ART's\n",
    "ProjectedGradientDescent class. The Projected Gradient Descent attack is an\n",
    "iterative method in which, after each iteration, the perturbation is projected\n",
    "on an lp-ball of specified radius (in addition to clipping the values of the\n",
    "adversarial sample so that it lies in the permitted data range). This is the\n",
    "[attack proposed by Madry et al.][paper] for adversarial training.\n",
    "\n",
    "The parameters here are as follows. The `classifier` is the type of model which is being attacked. `batch_size` is 1 which means only one adversarial example will be generated at a time. `eps` sets the epsilon value to .3 which is the size of the perturbation applied to the model. The goal of an attack is to try to change the model as much as possible with the smallest perturbation. `eps_step` is the attack step size, or input variation, at each iteration of the process. Here, we're using .007. `max_iter` is the maximum number of iterations of the process - in this case, 20. `num_random_init` is the number of random initializations within the epsilon ball. `random_eps` here is set to False which means we have a set epsilon. If this parameter were True, epsilon would be randomly drawn from a truncated normal distribution. (Literature suggests this for FGSM-based training to generalize across different epsilons, and then `eps_step` is modified to preserve the ratio of `eps`/`eps_step`)  Attacks can be targeted or untargeted which specifies whether the attack is designed to lead to a specific incorrect result or just anything other than the correct one. Here, we have `targeted` set to False which means we're just aiming for any wrong answer as output from the model. Finally, we have `verbose` set to False which means we don't need to see the progress bar and extra output.\n",
    "\n",
    "[art]: https://github.com/Trusted-AI/adversarial-robustness-toolbox\n",
    "[paper]: https://arxiv.org/abs/1706.06083"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "\n",
    "attack=track_init_params(ProjectedGradientDescent)(\n",
    "    classifier,\n",
    "    batch_size=1,\n",
    "    eps=0.3,\n",
    "    eps_step=0.007,\n",
    "    max_iter=20,\n",
    "    num_random_init=1,\n",
    "    random_eps=False,\n",
    "    targeted=False,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, `track_init_params` is used to output the initial metrics to MLflow. It\n",
    "takes as input the default specs for this attack.\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "Evaluations are what Armory is all about. They are essentially the testing of models with or without the application of an attack. An Armory evaluation contains all of the pertinent configuration details including the attack, dataset, model, metrics to collect, and host system configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import charmory.evaluation as ev\n",
    "from armory.metrics.compute import BasicProfiler\n",
    "\n",
    "evaluation = ev.Evaluation(\n",
    "    name=\"mnist-vit-pgd\",\n",
    "    description=\"MNIST image classification using a ViT model and PGD attack\",\n",
    "    author=\"TwoSix\",\n",
    "    dataset=ev.Dataset(\n",
    "        name=\"MNIST\",\n",
    "        x_key=\"data\",\n",
    "        y_key=\"target\",\n",
    "        test_dataloader=dataloader,\n",
    "    ),\n",
    "    model=ev.Model(\n",
    "        name=\"ViT\",\n",
    "        model=classifier,\n",
    "    ),\n",
    "    attack=ev.Attack(\n",
    "        name=\"PGD\",\n",
    "        attack=attack,\n",
    "        use_label_for_untargeted=False,\n",
    "    ),\n",
    "    metric=ev.Metric(profiler=BasicProfiler()),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we provide a name, description, and author of the evaluation. Then we create a Dataset for the evaluation using the `dataloader` defined previously around the Hugging Face data. The `x_key` and `y_key` names need to match what the dataset has. Similarly, the Model and Attack are based on the `classifier` model and `attack` defined previously. For the Metric, we'll use the `BasicProfiler` which outputs the average CPU time for each type of computation.\n",
    "\n",
    "### Task\n",
    "\n",
    "One of the last pieces here is the definition of the task to perform. Currently, Armory has two types of tasks: Image Classification and Object Detection. A task contains the evaluation configuration itself, as well as other details to include whether to skip the benign and/or attack datasets, an optional adapter to be applied to the inference data prior to exporting to MLflow, and a frequency at which batches will be exported to MLflow, if at all. The adapter we're using in this case is `Unnormalize` which is the inverse of the `torchvision.transforms.Normalize` transform. It takes as parameters a mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from charmory.tasks.image_classification import ImageClassificationTask\n",
    "from charmory.utils import Unnormalize\n",
    "\n",
    "task = ImageClassificationTask(\n",
    "        evaluation,\n",
    "        num_classes=10,\n",
    "        export_adapter=Unnormalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "        export_every_n_batches=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engine\n",
    "\n",
    "Finally, to actually run an evaluation, an Engine needs to be created. In Armory, there are currently two choices of engines: `EvaluationEngine` for performing model robustness evaluations as it pertains to adversarial attacks, and `AdversarialDatasetEngine` which creates an adversarial dataset by applying an attack to each sample in the original dataset. In this case, we already have an adversarial dataset, so we just need to start an `EvaluationEngine`. It takes as parameters the `task` which we defined above and `limit_test_batches` which we set to 16. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from charmory.engine import EvaluationEngine\n",
    "\n",
    "engine = EvaluationEngine(task, limit_test_batches=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
