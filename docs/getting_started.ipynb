{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite concepts in an Armory context\n",
    "\n",
    "### Dataset\n",
    "\n",
    "A dataset is a collection of images (samples) in a sequence-like structure such as a\n",
    "tuple, map, or numpy array. Each can have a target (label) assigned. Datasets can be\n",
    "imported from a variety of sources such as PyTorch, Hugging Face, or GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic\n",
    "\n",
    "The following is a basic example of loading tuple data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from charmory.data import TupleDataset\n",
    "\n",
    "raw_dataset = [\n",
    "        ([1, 2, 3], 4),\n",
    "        ([5, 6, 7], 8),\n",
    "    ]\n",
    "\n",
    "keyed_dataset = TupleDataset(raw_dataset, x_key=\"data\", y_key=\"target\")\n",
    "\n",
    "keyed_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see that we have turned the raw dataset into a map with keys \"data\" and\n",
    "\"target\". These keys are arbitrary; the same ones just need to be provided in\n",
    "the evaluation later and correspond to the images and labels respectively.\n",
    "\n",
    "For this dataset we need a adapter because ????."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def adapter(data):\n",
    "    # ??? What goes here?\n",
    "#dataset = ArmoryDataset(keyed_dataset, adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hugging Face\n",
    "\n",
    "The following is an example of how to load a dataset from [Hugging Face][huggingface]:\n",
    "\n",
    "[huggingface]: https://huggingface.co/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import datasets # Hugging Face dataset library\n",
    "\n",
    "from charmory.data import ArmoryDataLoader\n",
    "from charmory.track import tracking_context, track_param\n",
    "from transformers import AutoImageProcessor # Hugging Face image processor class\n",
    "\n",
    "track_param(\"global\", \"value\")\n",
    "\n",
    "with tracking_context():\n",
    "    # `global` parameter will not be recorded within this context\n",
    "    track_param(\"parent\", \"value\")\n",
    "\n",
    "    with tracking_context(nested=True):\n",
    "        track_param(\"child\", \"value\")\n",
    "        # This context contains both `parent` and `child` params, while the\n",
    "        # outer context still only has `parent`\n",
    "\n",
    "dataset = datasets.load_dataset(\"mnist\", split=\"test\")\n",
    "processor = AutoImageProcessor.from_pretrained(\n",
    "        \"farleyknight-org-username/vit-base-mnist\"  # Hugging Face model card\n",
    "    )\n",
    "\n",
    "def transform(processor, sample):\n",
    "    # Use the HF image processor and convert from BW To RGB\n",
    "    sample[\"image\"] = processor([img.convert(\"RGB\") for img in sample[\"image\"]])[\n",
    "        \"pixel_values\"\n",
    "    ]\n",
    "    return sample\n",
    "\n",
    "dataset.set_transform(functools.partial(transform, processor))\n",
    "dataloader = ArmoryDataLoader(dataset, batch_size=16, num_workers=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tracking_context` context manager will create a scoped session for the\n",
    "recording of parameters.\n",
    "\n",
    "The `load_dataset` functions imports the [MNIST][mnist] (handwritten digit)\n",
    "dataset from Hugging Face. It is the same dataset that was used to train the\n",
    "model in this example. The `split` parameter specifies which subset of the\n",
    "dataset to load, is usually either `train` or `test` or possibly `validation`,\n",
    "depending on the dataset.\n",
    "\n",
    "The function `transform` then cycles through the dataset and converts each image\n",
    "into Hugging Face's 'RGB' form. The `set_transform` method is used the the\n",
    "Hugging Face dataset and applied the transform function to the entire Hugging\n",
    "Face dataset.\n",
    "\n",
    "`AutoImageProcessor.from_pretrained` expects a Hugging Face name for the model\n",
    "card. Then the PyTorch `ArmoryDataLoader` generates the numpy arrays that are\n",
    "required by ART for the evaluation.\n",
    "\n",
    "[mnist]: https://huggingface.co/datasets/mnist\n",
    "\n",
    "### Model\n",
    "\n",
    "A model is the output of a machine learning algorithm run on a training set of\n",
    "data. It is used to identify patterns or make predictions on unseen datasets.\n",
    "Models can be imported from a variety of sources, including Hugging Face,\n",
    "GitHub, PyPI, and jatic_toolbox.\n",
    "\n",
    "#### Hugging Face\n",
    "\n",
    "The following is an example of how to import a model from Hugging Face:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "from charmory.model.image_classification import JaticImageClassificationModel\n",
    "from charmory.track import track_params\n",
    "\n",
    "model = JaticImageClassificationModel(\n",
    "        track_params(AutoModelForImageClassification.from_pretrained)(\n",
    "            \"farleyknight-org-username/vit-base-mnist\"\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `farleyknight-org-username/vit-base-mnist` is the Hugging Face model card\n",
    "name. `track_params` is a function wrapper that stores the argument values as\n",
    "parameters in MLflow and `JaticImageClassificationModel` is a wrapper to make\n",
    "the model compatible with Armory.\n",
    "\n",
    "#### GitHub\n",
    "\n",
    "The following is an example of how to import a model from GitHub, after having\n",
    "cloned the relevant repository:\n",
    "```\n",
    "git clone 'https://github.com/Lornatang/SRGAN-PyTorch'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import sys\n",
    "sys.path.insert(0,'/SRGAN-PyTorch')\n",
    "from SRGAN-PyTorch import model as pytorch_new_model\n",
    "\n",
    "SRRmodel = pytorch_new_model.SRResNet()\n",
    "\n",
    "model = JaticImageClassificationModel(\n",
    "    SRRmodel\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we add the GitHub folder to the system path and import the mode. Then, as\n",
    "in the last example, we use the `JaticImageClassificationModel` to make the\n",
    "model compatible with Armory.\n",
    "\n",
    "#### PyPI\n",
    "\n",
    "The following is an example of loading a model from the EfficientNet Lite\n",
    "PyTorch library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet_lite_pytorch import EfficientNet\n",
    "from efficientnet_lite0_pytorch_model import EfficientnetLite0ModelFile\n",
    "\n",
    "weights_path = EfficientnetLite0ModelFile.get_model_file_path()\n",
    "\n",
    "lite0_model = EfficientNet.from_pretrained('efficientnet-lite0', weights_path = weights_path )\n",
    "\n",
    "model = JaticImageClassificationModel(\n",
    "    lite0_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we import the library and create a model from the case with a weights path\n",
    "added.\n",
    "\n",
    "#### jatic_toolbox\n",
    "\n",
    "The following is an example of loading a Torchvision model from the jatic_toolbox:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jatic_toolbox import load_model \n",
    "\n",
    "model = track_params(load_model)(\n",
    "        provider=\"torchvision\",\n",
    "        model_name=\"resnet34\",\n",
    "        task=\"image-classification\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each case, we use the `PyTorchClassifier` wrapper to make the model\n",
    "compatible with the ART library. Note that this is specific to image\n",
    "classification models written within the PyTorch framework. The parameters can\n",
    "be adjusted as needed. `track_initial_params` is used so that these parameters\n",
    "are also tracked in MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "from charmory.track import track_init_params\n",
    "import torch\n",
    "\n",
    "classifier = track_init_params(PyTorchClassifier)(\n",
    "    model,\n",
    "    loss=torch.nn.CrossEntropyLoss(),\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=0.003),\n",
    "    input_shape=(3, 224, 224),\n",
    "    channels_first=True,\n",
    "    nb_classes=10,\n",
    "    clip_values=(-1, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack\n",
    "\n",
    "An attack is a transformation of (each sample in) the dataset in order to\n",
    "disrupt the machine learning algorithm's results. For example, after an attack,\n",
    "the model may misclassify an image or fail to detect an object. In Armory,\n",
    "targeted attacks are designed to focus on only one class at a time. This is how\n",
    "we test the adversarial robustness of a machine learning model.\n",
    "\n",
    "Attacks can be loaded from [IBM's Adversarial Robustness Toolbox][art].\n",
    "\n",
    "The following is an example of how to define an attack from ART's\n",
    "ProjectedGradientDescent class. The Projected Gradient Descent attack is an\n",
    "iterative method in which, after each iteration, the perturbation is projected\n",
    "on an lp-ball of specified radius (in addition to clipping the values of the\n",
    "adversarial sample so that it lies in the permitted data range). This is the\n",
    "[attack proposed by Madry et al.][paper] for adversarial training.\n",
    "\n",
    "[art]: https://github.com/Trusted-AI/adversarial-robustness-toolbox\n",
    "[paper]: https://arxiv.org/abs/1706.06083"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import art.attacks.evasion\n",
    "\n",
    "from charmory.evaluation import Attack\n",
    "\n",
    "attack = Attack(\n",
    "        name=\"PGD\",\n",
    "        attack=track_init_params(art.attacks.evasion.ProjectedGradientDescent)(\n",
    "            classifier,\n",
    "            batch_size=1,\n",
    "            eps=0.3,\n",
    "            eps_step=0.007,\n",
    "            max_iter=20,\n",
    "            num_random_init=1,\n",
    "            random_eps=False,\n",
    "            targeted=False,\n",
    "            verbose=False,\n",
    "        ),\n",
    "        use_label_for_untargeted=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, `track_init_params` is used to output the initial metrics to MLflow. It\n",
    "takes as input the default specs for this attack."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
