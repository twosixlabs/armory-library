{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite concepts in an Armory context\n",
    "\n",
    "### Dataset\n",
    "\n",
    "A dataset is a collection of images (samples) in a sequence-like structure such as a\n",
    "tuple, map, or numpy array. Each can have a target (label) assigned. Datasets can be\n",
    "imported from a variety of sources such as PyTorch, Hugging Face, or GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic\n",
    "\n",
    "The following is a basic example of loading tuple data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [1, 2, 3], 'target': 4}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from charmory.data import TupleDataset\n",
    "\n",
    "raw_dataset = [\n",
    "        ([1, 2, 3], 4),\n",
    "        ([5, 6, 7], 8),\n",
    "    ]\n",
    "\n",
    "keyed_dataset = TupleDataset(raw_dataset, x_key=\"data\", y_key=\"target\")\n",
    "\n",
    "keyed_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see that we have turned the raw dataset into a map with keys \"data\" and\n",
    "\"target\". These keys are arbitrary; the same ones just need to be provided in\n",
    "the evaluation later and correspond to the images and labels respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hugging Face\n",
    "\n",
    "The following is an example of how to load a dataset from [Hugging Face][huggingface]:\n",
    "\n",
    "[huggingface]: https://huggingface.co/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "import datasets # Hugging Face dataset library\n",
    "\n",
    "from charmory.data import ArmoryDataLoader\n",
    "from charmory.track import tracking_context, track_param\n",
    "from transformers import AutoImageProcessor # Hugging Face image processor class\n",
    "\n",
    "track_param(\"global\", \"value\")\n",
    "\n",
    "with tracking_context():\n",
    "    # `global` parameter will not be recorded within this context\n",
    "    track_param(\"parent\", \"value\")\n",
    "\n",
    "    with tracking_context(nested=True):\n",
    "        track_param(\"child\", \"value\")\n",
    "        # This context contains both `parent` and `child` params, while the\n",
    "        # outer context still only has `parent`\n",
    "\n",
    "dataset = datasets.load_dataset(\"mnist\", split=\"test\")\n",
    "processor = AutoImageProcessor.from_pretrained(\n",
    "        \"farleyknight-org-username/vit-base-mnist\"  # Hugging Face model card\n",
    "    )\n",
    "\n",
    "def transform(processor, sample):\n",
    "    # Use the HF image processor and convert from BW To RGB\n",
    "    sample[\"image\"] = processor([img.convert(\"RGB\") for img in sample[\"image\"]])[\n",
    "        \"pixel_values\"\n",
    "    ]\n",
    "    return sample\n",
    "\n",
    "dataset.set_transform(functools.partial(transform, processor))\n",
    "dataloader = ArmoryDataLoader(dataset, batch_size=16, num_workers=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tracking_context` context manager will create a scoped session for the\n",
    "recording of parameters.\n",
    "\n",
    "The `load_dataset` functions imports the [MNIST][mnist] (handwritten digit)\n",
    "dataset from Hugging Face. The `split` parameter specifies which subset of the\n",
    "dataset to load, is usually either `train` or `test` or possibly `validation`,\n",
    "depending on the dataset.\n",
    "\n",
    "The `processor` is needed to ensure the dataset is pre-processed into a form\n",
    "that can be inputted into the model. The path passed into this function is a\n",
    "Hugging Face model card location, but just the preprocessor is pulled in.\n",
    "\n",
    "The function `transform` then cycles through the dataset and converts each image\n",
    "into Hugging Face's 'RGB' form. The `set_transform` method is used the the\n",
    "Hugging Face dataset and applied the transform function to the entire Hugging\n",
    "Face dataset.\n",
    "\n",
    "`AutoImageProcessor.from_pretrained` expects a Hugging Face name for the model\n",
    "card. Then the PyTorch `ArmoryDataLoader` generates the numpy arrays that are\n",
    "required by ART for the evaluation.\n",
    "\n",
    "### Model\n",
    "\n",
    "A model is the output of a machine learning algorithm run on a training set of\n",
    "data. It is used to identify patterns or make predictions on unseen datasets.\n",
    "Models can be imported from a variety of sources, including Hugging Face,\n",
    "GitHub, PyPI, and jatic_toolbox.\n",
    "\n",
    "#### Hugging Face\n",
    "\n",
    "The following is an example of how to import a model from Hugging Face:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "from charmory.model.image_classification import JaticImageClassificationModel\n",
    "from charmory.track import track_params\n",
    "\n",
    "model = JaticImageClassificationModel(\n",
    "        track_params(AutoModelForImageClassification.from_pretrained)(\n",
    "            \"farleyknight-org-username/vit-base-mnist\"\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `farleyknight-org-username/vit-base-mnist` is the Hugging Face model card\n",
    "name. This model was trained on the same mnist dataset as we used above.\n",
    "`track_params` is a function wrapper that stores the argument values as\n",
    "parameters in MLflow and `JaticImageClassificationModel` is a wrapper to make\n",
    "the model compatible with Armory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jatic_toolbox import load_model \n",
    "\n",
    "model = track_params(load_model)(\n",
    "        provider=\"torchvision\",\n",
    "        model_name=\"resnet34\",\n",
    "        task=\"image-classification\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the `PyTorchClassifier` wrapper to make the model compatible with\n",
    "the ART library. Note that this is specific to image classification models\n",
    "written within the PyTorch framework. The parameters can be adjusted as needed.\n",
    "`track_initial_params` is used so that these parameters are also tracked in\n",
    "MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "from charmory.track import track_init_params\n",
    "import torch\n",
    "\n",
    "classifier = track_init_params(PyTorchClassifier)(\n",
    "    model,\n",
    "    loss=torch.nn.CrossEntropyLoss(),\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=0.003),\n",
    "    input_shape=(3, 224, 224),\n",
    "    channels_first=True,\n",
    "    nb_classes=10,\n",
    "    clip_values=(-1, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other\n",
    "\n",
    "To see examples of importing models from other places such as GitHub and PyPI,\n",
    "please see the auxiliary notebook, [Diving Deeper][colab-diving-deeper].\n",
    "\n",
    "[colab-diving-deeper]: https://colab.research.google.com/github/twosixlabs/armory-library/blob/master/docs/diving_deeper.ipynb\n",
    "\n",
    "### Attack\n",
    "\n",
    "An attack is a transformation of (each sample in) the dataset in order to\n",
    "disrupt the machine learning algorithm's results. For example, after an attack,\n",
    "the model may misclassify an image or fail to detect an object. In Armory,\n",
    "targeted attacks are designed to focus on only one class at a time. This is how\n",
    "we test the adversarial robustness of a machine learning model.\n",
    "\n",
    "Attacks can be loaded from [IBM's Adversarial Robustness Toolbox][art].\n",
    "\n",
    "The following is an example of how to define an attack from ART's\n",
    "ProjectedGradientDescent class. The Projected Gradient Descent attack is an\n",
    "iterative method in which, after each iteration, the perturbation is projected\n",
    "on an lp-ball of specified radius (in addition to clipping the values of the\n",
    "adversarial sample so that it lies in the permitted data range). This is the\n",
    "[attack proposed by Madry et al.][paper] for adversarial training.\n",
    "\n",
    "[art]: https://github.com/Trusted-AI/adversarial-robustness-toolbox\n",
    "[paper]: https://arxiv.org/abs/1706.06083"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import art.attacks.evasion\n",
    "\n",
    "from charmory.evaluation import Attack\n",
    "\n",
    "attack = Attack(\n",
    "        name=\"PGD\",\n",
    "        attack=track_init_params(art.attacks.evasion.ProjectedGradientDescent)(\n",
    "            classifier,\n",
    "            batch_size=1,\n",
    "            eps=0.3,\n",
    "            eps_step=0.007,\n",
    "            max_iter=20,\n",
    "            num_random_init=1,\n",
    "            random_eps=False,\n",
    "            targeted=False,\n",
    "            verbose=False,\n",
    "        ),\n",
    "        use_label_for_untargeted=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, `track_init_params` is used to output the initial metrics to MLflow. It\n",
    "takes as input the default specs for this attack.\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "Evaluations are what Armory is all about. They are essentially the testing of models with or without the application of an attack. An Armory evaluation contains all of the pertinent configuration details including the attack, dataset, model, metrics to collect, and host system configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Evaluation attack is not an instance of EvasionAttack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/Armory/armory-library/docs/getting_started.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blori.armory-library.org/home/ubuntu/Armory/armory-library/docs/getting_started.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39marmory\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompute\u001b[39;00m \u001b[39mimport\u001b[39;00m BasicProfiler\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blori.armory-library.org/home/ubuntu/Armory/armory-library/docs/getting_started.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharmory\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevaluation\u001b[39;00m \u001b[39mimport\u001b[39;00m Evaluation\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blori.armory-library.org/home/ubuntu/Armory/armory-library/docs/getting_started.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m evaluation \u001b[39m=\u001b[39m Evaluation(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blori.armory-library.org/home/ubuntu/Armory/armory-library/docs/getting_started.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmnist-vit-pgd\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blori.armory-library.org/home/ubuntu/Armory/armory-library/docs/getting_started.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     description\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMNIST image classification using a ViT model and PGD attack\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blori.armory-library.org/home/ubuntu/Armory/armory-library/docs/getting_started.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     author\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTwoSix\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blori.armory-library.org/home/ubuntu/Armory/armory-library/docs/getting_started.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     dataset\u001b[39m=\u001b[39mev\u001b[39m.\u001b[39mDataset(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blori.armory-library.org/home/ubuntu/Armory/armory-library/docs/getting_started.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m         name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMNIST\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blori.armory-library.org/home/ubuntu/Armory/armory-library/docs/getting_started.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m         x_key\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blori.armory-library.org/home/ubuntu/Armory/armory-library/docs/getting_started.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m         y_key\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blori.armory-library.org/home/ubuntu/Armory/armory-library/docs/getting_started.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m         test_dataloader\u001b[39m=\u001b[39mdataloader,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blori.armory-library.org/home/ubuntu/Armory/armory-library/docs/getting_started.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     ),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blori.armory-library.org/home/ubuntu/Armory/armory-library/docs/getting_started.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     model\u001b[39m=\u001b[39mev\u001b[39m.\u001b[39mModel(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blori.armory-library.org/home/ubuntu/Armory/armory-library/docs/getting_started.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m         name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mViT\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blori.armory-library.org/home/ubuntu/Armory/armory-library/docs/getting_started.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m         model\u001b[39m=\u001b[39mclassifier,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blori.armory-library.org/home/ubuntu/Armory/armory-library/docs/getting_started.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     ),\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blori.armory-library.org/home/ubuntu/Armory/armory-library/docs/getting_started.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     attack\u001b[39m=\u001b[39mev\u001b[39m.\u001b[39;49mAttack(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blori.armory-library.org/home/ubuntu/Armory/armory-library/docs/getting_started.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m         name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPGD\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blori.armory-library.org/home/ubuntu/Armory/armory-library/docs/getting_started.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m         attack\u001b[39m=\u001b[39;49mattack,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blori.armory-library.org/home/ubuntu/Armory/armory-library/docs/getting_started.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m         use_label_for_untargeted\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blori.armory-library.org/home/ubuntu/Armory/armory-library/docs/getting_started.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     ),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blori.armory-library.org/home/ubuntu/Armory/armory-library/docs/getting_started.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     metric\u001b[39m=\u001b[39mev\u001b[39m.\u001b[39mMetric(profiler\u001b[39m=\u001b[39mBasicProfiler()),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blori.armory-library.org/home/ubuntu/Armory/armory-library/docs/getting_started.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m )\n",
      "File \u001b[0;32m<string>:8\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, name, attack, generate_kwargs, use_label_for_untargeted, label_targeter)\u001b[0m\n",
      "File \u001b[0;32m~/Armory/armory-library/library/src/charmory/evaluation.py:42\u001b[0m, in \u001b[0;36mAttack.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__post_init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 42\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m     43\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattack, EvasionAttack\n\u001b[1;32m     44\u001b[0m     ), \u001b[39m\"\u001b[39m\u001b[39mEvaluation attack is not an instance of EvasionAttack\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargeted:\n\u001b[1;32m     47\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m     48\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_targeter, LabelTargeter\n\u001b[1;32m     49\u001b[0m         ), \u001b[39m\"\u001b[39m\u001b[39mEvaluation attack\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms label_targeter is not an instance of LabelTargeter\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Evaluation attack is not an instance of EvasionAttack"
     ]
    }
   ],
   "source": [
    "from armory.metrics.compute import BasicProfiler\n",
    "from charmory.evaluation import Evaluation\n",
    "\n",
    "evaluation = Evaluation(\n",
    "    name=\"mnist-vit-pgd\",\n",
    "    description=\"MNIST image classification using a ViT model and PGD attack\",\n",
    "    author=\"TwoSix\",\n",
    "    dataset=ev.Dataset(\n",
    "        name=\"MNIST\",\n",
    "        x_key=\"data\",\n",
    "        y_key=\"target\",\n",
    "        test_dataloader=dataloader,\n",
    "    ),\n",
    "    model=ev.Model(\n",
    "        name=\"ViT\",\n",
    "        model=classifier,\n",
    "    ),\n",
    "    attack=ev.Attack(\n",
    "        name=\"PGD\",\n",
    "        attack=attack,\n",
    "        use_label_for_untargeted=False,\n",
    "    ),\n",
    "    metric=ev.Metric(profiler=BasicProfiler()),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we provide a name, description, and author of the evaluation. Then we create a Dataset for the evaluation using the `dataloader` defined previously around the Hugging Face data. The `x_key` and `y_key` names need to match what the dataset has. Similarly, the Model and Attack are based on the `classifier` model and `attack` defined previously. For the Metric, we'll use the `BasicProfiler` which outputs the average CPU time for each type of computation.\n",
    "\n",
    "### Task\n",
    "\n",
    "One of the last pieces here is the definition of the task to perform. Currently, Armory has two types of tasks: Image Classification and Object Detection. A task contains the evaluation configuration itself, as well as other details to include whether to skip the benign and/or attack datasets, an optional adapter to be applied to the inference data prior to exporting to MLflow, and a frequency at which batches will be exported to MLflow, if at all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from charmory.tasks.image_classification import ImageClassificationTask\n",
    "\n",
    "task = ImageClassificationTask(\n",
    "        evaluation,\n",
    "        num_classes=10,\n",
    "        export_adapter=Unnormalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "        export_every_n_batches=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engine\n",
    "\n",
    "Finally, to actually run an evaluation, an Engine needs to be created. In Armory, there are currently two choices of engines: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from charmory.engine import EvaluationEngine\n",
    "\n",
    "engine = EvaluationEngine(task, limit_test_batches=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
