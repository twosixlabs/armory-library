{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch vision example\n",
    "\n",
    "Source: https://www.learnopencv.com/pytorch-for-beginners-image-classification-using-pre-trained-models/\n",
    "with minor modifications. Errors are likely mine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "\n",
    "# Let us look at the Deep learning architectures implemented in the torch vision library.\n",
    "dir(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there is one entry called **AlexNet** and one called **alexnet**. The capitalised name refers to the Python class (AlexNet) whereas alexnet is a convenience function that returns the model instantiated from the AlexNet class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.alexnet import AlexNet_Weights\n",
    "\n",
    "alexnet = models.alexnet(weights=AlexNet_Weights.DEFAULT)\n",
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = Image.open(Path('./dog.jpg'))\n",
    "\n",
    "plt.imshow(img)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.resize((256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "transform = transforms.Compose([        # Defining a variable transforms\n",
    " transforms.Resize(256),                # Resize the image to 256×256 pixels\n",
    " transforms.CenterCrop(224),            # Crop the image to 224×224 pixels about the center\n",
    " transforms.ToTensor(),                 # Convert the image to PyTorch Tensor data type\n",
    " transforms.Normalize(                  # Normalize the image\n",
    " mean=[0.485, 0.456, 0.406],            # Mean and std of image as also used when training the network\n",
    " std=[0.229, 0.224, 0.225]\n",
    " )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t = transform(img)\n",
    "img_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_t = torch.unsqueeze(img_t, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = alexnet(batch_t)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "raw_classes = json.load(open(Path('./imagenet_classes.json')))[\"imagenet_classes\"]\n",
    "assert len(classes) == 1000 and classes[11] == 'goldfinch'\n",
    "classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, indices = torch.sort(out, descending=True)\n",
    "percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
    "[(classes[idx], percentage[idx].item()) for idx in indices[0][:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# running testing alexnet with stl10 torchvision dataset\n",
    "\n",
    "As it happens, the INaturalist dataset was good for our purposes but way too big.\n",
    "As [the STL-10 page notes](https://cs.stanford.edu/~acoates/stl10/) these\n",
    "images were drawn from ImageNet so presumably are readily recognized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from charmory.evaluation import SysConfig\n",
    "from torchvision.datasets import STL10\n",
    "\n",
    "root = SysConfig().dataset_cache / 'stl10'\n",
    "stl = STL10(root=root, split='test', download=True)\n",
    "\n",
    "print(stl[0])\n",
    "img, label = stl[0]\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
