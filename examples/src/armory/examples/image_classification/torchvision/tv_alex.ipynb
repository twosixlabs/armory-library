{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch vision example\n",
    "\n",
    "Source: https://www.learnopencv.com/pytorch-for-beginners-image-classification-using-pre-trained-models/\n",
    "with minor modifications. Errors are likely mine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "\n",
    "# Let us look at the Deep learning architectures implemented in the torch vision library.\n",
    "dir(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there is one entry called **AlexNet** and one called **alexnet**. The capitalised name refers to the Python class (AlexNet) whereas alexnet is a convenience function that returns the model instantiated from the AlexNet class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.alexnet import AlexNet_Weights\n",
    "\n",
    "alexnet = models.alexnet(weights=AlexNet_Weights.DEFAULT)\n",
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import json\n",
    "\n",
    "def imagenet_class(idx: int, cache=None):\n",
    "    if cache is None:\n",
    "        cache = json.load(open(Path('./imagenet_classes.json')))[\"imagenet_classes\"]\n",
    "        assert len(cache) == 1000 and cache[11] == 'goldfinch'\n",
    "\n",
    "    return cache[idx]\n",
    "\n",
    "transform = transforms.Compose([        # Defining a variable transforms\n",
    "   transforms.Resize(256),                # Resize the image to 256×256 pixels\n",
    "   transforms.CenterCrop(224),            # Crop the image to 224×224 pixels about the center\n",
    "   transforms.ToTensor(),                 # Convert the image to PyTorch Tensor data type\n",
    "   transforms.Normalize(                  # Normalize the image\n",
    "   mean=[0.485, 0.456, 0.406],            # Mean and std of image as also used when training the network\n",
    "   std=[0.229, 0.224, 0.225]\n",
    " )])\n",
    "\n",
    "def evaluate_image(img):\n",
    "    img_t = transform(img)                # Apply the transformations on the image\n",
    "    batch_t = torch.unsqueeze(img_t, 0)   # Add a batch dimension to the image\n",
    "    alexnet.eval()                        # Set the network to evaluation mode\n",
    "    out = alexnet(batch_t)                # Forward propagate the image\n",
    "\n",
    "    _, indices = torch.sort(out, descending=True)\n",
    "    percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
    "    return [(imagenet_class(idx), percentage[idx].item()) for idx in indices[0][:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(Path('./dog.jpg'))\n",
    "best = evaluate_image(img)\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# running testing alexnet with stl10 torchvision dataset\n",
    "\n",
    "As it happens, the INaturalist dataset was good for our purposes but way too big.\n",
    "As [the STL-10 page notes](https://cs.stanford.edu/~acoates/stl10/) these\n",
    "images were drawn from ImageNet so presumably are readily recognized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from charmory.evaluation import SysConfig\n",
    "from torchvision.datasets import STL10\n",
    "from pprint import pprint\n",
    "\n",
    "root = SysConfig().dataset_cache / 'stl10'\n",
    "stl = STL10(root=root, split='test', download=True)\n",
    "\n",
    "stl_classes = 'airplane, bird, car, cat, deer, dog, horse, monkey, ship, truck'.split(', ')\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    img, label = stl[i]\n",
    "    target = stl_classes[label]\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    print(f\"{label=}, {target=}\")\n",
    "    best = evaluate_image(img)\n",
    "    pprint(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that didn't work. There are only 10 classes in STL-10 and the model outputs\n",
    "1000 classes. As shown in the first output from the cell above, the first STL item\n",
    "is a horse, but imagenet has no horse class. So we get the most likely as \"oxcart\"\n",
    "which isn't a bad guess, but it is not a horse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using Imagenet-1k dataset\n",
    "\n",
    "The Imagenet-1k dataset in torchvision requires tarfiles downloaded from image-net.org,\n",
    "but I've applied to get access and it takes \"up to 5 days\". So I've downloaded parquet\n",
    "files for the same dataset and have stashed them on our \n",
    "s3://armory-library-data/datasets/huggingface/imagenet/ so at least I don't have to\n",
    "hunt them down again.\n",
    "\n",
    "This means that I'm going to use a huggingface dataloader for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "dataset_local = str(SysConfig().dataset_cache / 'imagenet-1k/validation_split')\n",
    "imagenet = pq.ParquetDataset(dataset_local)\n",
    "table = imagenet.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in table:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = table['label'][0]\n",
    "img_data = table['image'][0]\n",
    "print(f\"{target=} {type(img_data)=}\")\n",
    "print(f\"{img_data.type=} {img_data.keys=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
