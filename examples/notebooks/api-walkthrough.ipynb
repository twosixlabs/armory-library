{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Armory Evaluation Declarations, Composition, and Modification\n",
                "\n",
                "There are data declarations in charmory.blocks that recapitulate standard evaluations\n",
                "from the armory package. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "2023-07-26 16:26:20  3s \u001b[33m\u001b[1mWARNING \u001b[0m \u001b[36mlogging\u001b[0m:\u001b[36mcallHandlers\u001b[0m:\u001b[36m1706\u001b[0m `tfds.core.add_checksums_dir` is deprecated. Refactor dataset in self-contained folders (`my_dataset/` folder containing my_dataset.py, my_dataset_test.py, dummy_data/, checksums.tsv). The checksum file will be automatically detected. More info at: https://www.tensorflow.org/datasets/add_dataset\n"
                    ]
                }
            ],
            "source": [
                "import charmory.blocks.cifar10\n",
                "\n",
                "baseline = charmory.blocks.cifar10.baseline"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The `baseline` evaluation is a composite dataclass with some metadata fields\n",
                "describing the evaluation:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\"type(baseline)=<class 'charmory.evaluation.Evaluation'>\"\n",
                        "(\"baseline.name='cifar_baseline'\\n\"\n",
                        " \"baseline.description='Baseline cifar10 image classification'\\n\"\n",
                        " \"baseline.author='msw@example.com'\")\n"
                    ]
                }
            ],
            "source": [
                "from pprint import pprint\n",
                "pprint(f\"{type(baseline)=}\")\n",
                "pprint(f\"{baseline.name=}\\n{baseline.description=}\\n{baseline.author=}\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The charmory `Evaluation` class was called \"Experiment\" in prior versions of the\n",
                "JATIC Armory library, but was renamed to avoid confusion with the MLflow conception\n",
                "of Experiment, which is a collection of runs.\n",
                "\n",
                "Along with the metadata, an `Evaluation` contains some required components. The\n",
                "`dataset` is a `Dataset` object, which specifies an Armory dataset and a pair\n",
                "of necessary parameters:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(\"baseline.dataset=Dataset(name='CIFAR10', \"\n",
                        " 'test_dataset=<armory.data.datasets.ArmoryDataGenerator object at '\n",
                        " '0x7fe2e80ab050>, train_dataset=<armory.data.datasets.ArmoryDataGenerator '\n",
                        " 'object at 0x7fe2e9c92990>)')\n"
                    ]
                }
            ],
            "source": [
                "pprint(f\"{baseline.dataset=}\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                " \n",
                "the `function` parameter is shown first while details come afterwards; this allows quick\n",
                "visibility of \"this is a cifar10 dataset\" from the `__str__` representation of the\n",
                "object. An `Evaluation` also requires a `Model` and `Scenario`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(\"baseline.model=Model(name='pytorch cifar', \"\n",
                        " 'model=art.estimators.classification.pytorch.PyTorchClassifier(model=ModelWrapper(\\n'\n",
                        " '  (_model): Net(\\n'\n",
                        " '    (conv1): Conv2d(3, 4, kernel_size=(5, 5), stride=(1, 1))\\n'\n",
                        " '    (conv2): Conv2d(4, 10, kernel_size=(5, 5), stride=(1, 1))\\n'\n",
                        " '    (fc1): Linear(in_features=250, out_features=100, bias=True)\\n'\n",
                        " '    (fc2): Linear(in_features=100, out_features=10, bias=True)\\n'\n",
                        " '  )\\n'\n",
                        " '), loss=CrossEntropyLoss(), optimizer=Adam (\\n'\n",
                        " 'Parameter Group 0\\n'\n",
                        " '    amsgrad: False\\n'\n",
                        " '    betas: (0.9, 0.999)\\n'\n",
                        " '    capturable: False\\n'\n",
                        " '    differentiable: False\\n'\n",
                        " '    eps: 1e-08\\n'\n",
                        " '    foreach: None\\n'\n",
                        " '    fused: None\\n'\n",
                        " '    lr: 0.003\\n'\n",
                        " '    maximize: False\\n'\n",
                        " '    weight_decay: 0\\n'\n",
                        " '), input_shape=(32, 32, 3), nb_classes=10, channels_first=False, '\n",
                        " 'clip_values=array([0., 1.], dtype=float32), preprocessing_defences=None, '\n",
                        " 'postprocessing_defences=None, '\n",
                        " 'preprocessing=StandardisationMeanStdPyTorch(mean=0.0, std=1.0, '\n",
                        " 'apply_fit=True, apply_predict=True, device=cuda:0)), predict_kwargs={})')\n",
                        "('baseline.scenario=Scenario(function=<class '\n",
                        " \"'charmory.scenarios.image_classification.ImageClassificationTask'>, \"\n",
                        " 'kwargs={}, export_batches=True)')\n"
                    ]
                }
            ],
            "source": [
                "pprint(f\"{baseline.model=}\")\n",
                "pprint(f\"{baseline.scenario=}\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Here we are using a prefab ART model and the standard Armory Image Classification Task\n",
                "scenario.\n",
                "\n",
                "Because this is a \"baseline\" evaluation, it includes no defense, but does use a PGD\n",
                "attack to calculate adversarial results.\n",
                "\n",
                "The optional `Metric` field tells Armory that we want to record additional metrics for\n",
                "this evaluation. In this case, we are interested in the accuracy of the model on\n",
                "adversarial examples."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "('baseline.attack=Attack(function=<class '\n",
                        " \"'art.attacks.evasion.projected_gradient_descent.projected_gradient_descent.ProjectedGradientDescent'>, \"\n",
                        " \"kwargs={'batch_size': 1, 'eps': 0.031, 'eps_step': 0.007, 'max_iter': 20, \"\n",
                        " \"'num_random_init': 1, 'random_eps': False, 'targeted': False, 'verbose': \"\n",
                        " \"False}, knowledge='white', use_label=True, type=None, generate_kwargs={}, \"\n",
                        " 'sweep_params={}, targeted=False, targeted_labels={})')\n",
                        "(\"baseline.metric=Metric(profiler_type='basic', \"\n",
                        " \"supported_metrics=['accuracy'], perturbation=['linf'], \"\n",
                        " \"task=['categorical_accuracy'], means=True, record_metric_per_sample=False)\")\n"
                    ]
                }
            ],
            "source": [
                "pprint(f\"{baseline.attack=}\")\n",
                "pprint(f\"{baseline.metric=}\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The `charmory.blocks` module is intended as a convenient parts cabinet that allows\n",
                "users to quickly assemble evaluations using standard components. They behave as standard\n",
                "Python objects, so you can alter the canned definitions:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "baseline.metric = None"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If you'd prefer to not have additional tracking. Also, the sub-components of an evaluation\n",
                "are themselves objects, to be composed at user discretion:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "charmory.blocks.cifar10.metric=Metric(profiler_type='basic', supported_metrics=['accuracy'], perturbation=['linf'], task=['categorical_accuracy'], means=True, record_metric_per_sample=False)\n"
                    ]
                }
            ],
            "source": [
                "print(f\"{charmory.blocks.cifar10.metric=}\")\n",
                "\n",
                "# let's put the metric back into baseline\n",
                "baseline.metric = charmory.blocks.cifar10.metric"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Instantiation of the `Engine` class using the `Evaluation` object in `baseline` is\n",
                "straightforward:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "import charmory.engine\n",
                "engine = charmory.engine.Engine(baseline)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Evaluation: 100%|██████████| 157/157 [09:53<00:00,  3.78s/it]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "2023-07-26 16:36:16 10m \u001b[34mMETRIC  \u001b[0m \u001b[36marmory.instrument.instrument\u001b[0m:\u001b[36m_write\u001b[0m:\u001b[36m743\u001b[0m benign_mean_categorical_accuracy on benign examples w.r.t. ground truth labels: 0.0999\n",
                        "2023-07-26 16:36:16 10m \u001b[34mMETRIC  \u001b[0m \u001b[36marmory.instrument.instrument\u001b[0m:\u001b[36m_write\u001b[0m:\u001b[36m743\u001b[0m adversarial_mean_categorical_accuracy on adversarial examples w.r.t. ground truth labels: 0.0773\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "result = engine.run()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'armory_version': '23.4.0.post113+g0e7be67a.d20230713',\n",
                        " 'evaluation': Evaluation(name='cifar_baseline',\n",
                        "                          description='Baseline cifar10 image classification',\n",
                        "                          model=Model(name='pytorch cifar',\n",
                        "                                      model=art.estimators.classification.pytorch.PyTorchClassifier(model=ModelWrapper(\n",
                        "  (_model): Net(\n",
                        "    (conv1): Conv2d(3, 4, kernel_size=(5, 5), stride=(1, 1))\n",
                        "    (conv2): Conv2d(4, 10, kernel_size=(5, 5), stride=(1, 1))\n",
                        "    (fc1): Linear(in_features=250, out_features=100, bias=True)\n",
                        "    (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
                        "  )\n",
                        "), loss=CrossEntropyLoss(), optimizer=Adam (\n",
                        "Parameter Group 0\n",
                        "    amsgrad: False\n",
                        "    betas: (0.9, 0.999)\n",
                        "    capturable: False\n",
                        "    differentiable: False\n",
                        "    eps: 1e-08\n",
                        "    foreach: None\n",
                        "    fused: None\n",
                        "    lr: 0.003\n",
                        "    maximize: False\n",
                        "    weight_decay: 0\n",
                        "), input_shape=(32, 32, 3), nb_classes=10, channels_first=False, clip_values=array([0., 1.], dtype=float32), preprocessing_defences=None, postprocessing_defences=None, preprocessing=StandardisationMeanStdPyTorch(mean=0.0, std=1.0, apply_fit=True, apply_predict=True, device=cuda:0)),\n",
                        "                                      predict_kwargs={}),\n",
                        "                          scenario=Scenario(function=<class 'charmory.scenarios.image_classification.ImageClassificationTask'>,\n",
                        "                                            kwargs={},\n",
                        "                                            export_batches=True),\n",
                        "                          dataset=Dataset(name='CIFAR10',\n",
                        "                                          test_dataset=<armory.data.datasets.ArmoryDataGenerator object at 0x7fe2e80ab050>,\n",
                        "                                          train_dataset=<armory.data.datasets.ArmoryDataGenerator object at 0x7fe2e9c92990>),\n",
                        "                          author='msw@example.com',\n",
                        "                          attack=Attack(function=<class 'art.attacks.evasion.projected_gradient_descent.projected_gradient_descent.ProjectedGradientDescent'>,\n",
                        "                                        kwargs={'batch_size': 1,\n",
                        "                                                'eps': 0.031,\n",
                        "                                                'eps_step': 0.007,\n",
                        "                                                'max_iter': 20,\n",
                        "                                                'num_random_init': 1,\n",
                        "                                                'random_eps': False,\n",
                        "                                                'targeted': False,\n",
                        "                                                'verbose': False},\n",
                        "                                        knowledge='white',\n",
                        "                                        use_label=True,\n",
                        "                                        type=None,\n",
                        "                                        generate_kwargs={},\n",
                        "                                        sweep_params={},\n",
                        "                                        targeted=False,\n",
                        "                                        targeted_labels={}),\n",
                        "                          metric=Metric(profiler_type='basic',\n",
                        "                                        supported_metrics=['accuracy'],\n",
                        "                                        perturbation=['linf'],\n",
                        "                                        task=['categorical_accuracy'],\n",
                        "                                        means=True,\n",
                        "                                        record_metric_per_sample=False),\n",
                        "                          sysconfig=SysConfig(gpus=['all'], use_gpu=True)),\n",
                        " 'results': {'adversarial_mean_categorical_accuracy': [0.0773],\n",
                        "             'benign_mean_categorical_accuracy': [0.0999],\n",
                        "             'compute': {'Avg. CPU time (s) for 157 executions of Attack': 3.6688439361337464,\n",
                        "                         'Avg. CPU time (s) for 157 executions of Inference': 0.013240570993672287},\n",
                        "             'perturbation_mean_linf': [0.03100001811236143]},\n",
                        " 'timestamp': 1690403183}\n"
                    ]
                }
            ],
            "source": [
                "from pprint import pprint\n",
                "pprint(result)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Recap\n",
                "\n",
                "There is a bunch of explanation and debug prints in this notebook, but the\n",
                "working code used is quite short:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import charmory.blocks.cifar10\n",
                "import charmory.engine\n",
                "\n",
                "baseline = charmory.blocks.cifar10.baseline\n",
                "engine = charmory.engine.Engine(baseline)\n",
                "result = engine.run()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
