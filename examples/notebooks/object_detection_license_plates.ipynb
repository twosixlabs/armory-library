{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Perform all necessary imports up front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python standard imports\n",
    "from pprint import pprint\n",
    "\n",
    "# armory-library imports\n",
    "import armory.engine\n",
    "import armory.evaluation\n",
    "import armory.utils\n",
    "\n",
    "# armory-examples imports\n",
    "import armory.examples.object_detection.license_plates_yolos as license_plates\n",
    "from armory.examples.utils.display import display_object_detection_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "num_batches = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define some runtime parameters here. These can be overwritten externally\n",
    "via papermill (e.g., `-p batch_size 4`). Modify these as necessary based on your\n",
    "host resource constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = armory.evaluation.Evaluation(\n",
    "    name=\"object-detection-license-plates\",\n",
    "    description=\"Object detection of license-plates\",\n",
    "    author=\"TwoSix\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "From our YOLOS license plates example, we will load a model from HuggingFace\n",
    "that has already been fine-tuned on the roboflow license plates dataset. We also\n",
    "wrap this model in an Adversarial Robustness Toolbox (ART) estimator so that we\n",
    "can use an ART attack against the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with evaluation.autotrack():\n",
    "    model, art_estimator = license_plates.load_model()\n",
    "evaluation.use_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "From our YOLOS license plates example, we will load the roboflow license plates\n",
    "dataset from HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with evaluation.autotrack():\n",
    "    dataset = license_plates.load_dataset(batch_size=batch_size, shuffle=False)\n",
    "evaluation.use_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack\n",
    "\n",
    "From our YOLOS license plates example, we create a robust DPatch attack using\n",
    "the Adversarial Robustness Toolbox (ART)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with evaluation.autotrack():\n",
    "    attack = license_plates.create_attack(art_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "From our YOLOS license plates example, we create the metrics to be collected\n",
    "during the evaluation. These include an L-infinity norm distance between\n",
    "unperturbed and perturbed input, and a mean average precision between the\n",
    "natural objects and the predicted objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.use_metrics(\n",
    "    license_plates.create_metrics()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporters\n",
    "\n",
    "From our YOLOS license plates example, we create the exporters used to record\n",
    "sample images during the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.use_exporters(\n",
    "    license_plates.create_exporters(model, export_every_n_batches=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Chains\n",
    "\n",
    "We will define two perturbation chains: `benign` and `attack`. The benign chain\n",
    "does not apply any perturbations to the data, giving us the intrinsic\n",
    "performance of the model. The attack chain will give us the performance of the\n",
    "model under adversarial attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with evaluation.add_chain(\"benign\"):\n",
    "    pass\n",
    "\n",
    "with evaluation.add_chain(\"attack\") as chain:\n",
    "    chain.add_perturbation(attack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the Evaluation\n",
    "\n",
    "We create an evaluation engine which will handle the application of all\n",
    "perturbations, obtaining predictions from the model, collecting metrics, and\n",
    "exporting of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = armory.engine.EvaluationEngine(\n",
    "    evaluation,\n",
    "    limit_test_batches=num_batches,\n",
    ")\n",
    "results = engine.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [],
   "source": [
    "pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [],
   "source": [
    "display_object_detection_results(\n",
    "    chains={name: res[\"run_id\"] for name, res in results.items()},\n",
    "    batch_idx=0,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
