{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d54701f8d4ec1b88",
   "metadata": {},
   "source": [
    "# New Image Classification Dataset\n",
    "\n",
    "This notebook describes the process of preparing a user-provided image classification dataset (one not included in Hugging Face or Torchvision) for use in Armory Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from pathlib import Path\n",
    "\n",
    "import datasets\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "import armory.data\n",
    "import armory.dataset\n",
    "import armory.evaluation\n",
    "import armory.examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4580ee8c3cd391f5",
   "metadata": {},
   "source": [
    "[SAMPLE Public Dataset](https://github.com/benjaminlewis-afrl/SAMPLE_dataset_public)\n",
    "\n",
    "The SAMPLE dataset (Synthetic and Measured Paired Labeled Experiment) dataset consists of measured SAR imagery from the MSTAR collection (Moving and Stationary Target Acquisition and Recognition) paired with synthetic SAR imagery. The public version of this dataset contains data with azimuth angles between 10 and 80 degrees.\n",
    "\n",
    "The MSTAR dataset contains SAR imagery of 10 types of military vehicles illustrated in the EO images below.\n",
    "\n",
    "<img src=\"mstar_10_targets.png\"\n",
    "    alt=\"MSTAR 10 Targets\"\n",
    "    width=\"700\">\n",
    "\n",
    "[Song, Haibo & Ji, Kefeng & Zhang, Yunshu & Xing, Xiang & Zou, Huanxin. (2016). Sparse Representation-Based SAR Image Target Classification on the 10-Class MSTAR Data Set. Applied Sciences. 6. 26. 10.3390/app6010026.](https://www.mdpi.com/2076-3417/6/1/26)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eefc985f04a5361",
   "metadata": {},
   "source": [
    "## Download dataset\n",
    "\n",
    "As a first step, we clone the [SAMPLE dataset repository](https://github.com/benjaminlewis-afrl/SAMPLE_dataset_public) that contains the real and synthetic SAR imagery into a temporary location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b136590356225d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = Path('/tmp')\n",
    "sample_dir = tmp_dir / Path('SAMPLE_dataset_public')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8de43c8d2efa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s $sample_dir\n",
    "\n",
    "if [[ -d $1 ]]\n",
    "then\n",
    "    echo \"$1 exists\"\n",
    "else\n",
    "    git clone https://github.com/benjaminlewis-afrl/SAMPLE_dataset_public $1\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa50c07269b3fe95",
   "metadata": {},
   "source": [
    "### Dataset structure\n",
    "\n",
    "The SAMPLE dataset is organized according to the [`ImageFolder`](https://huggingface.co/docs/datasets/v2.19.0/en/image_dataset#imagefolder) pattern. The imagery is split into two normalizations -- decibel and quarter power magnitude (QPM). For each normalization type, real and synthetic SAR imagery is partitioned into folders according to vehicle type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4cd6502ccbe046",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find $sample_dir -type d -not -path \"$sample_dir/.git*\" -not -path \"$sample_dir/mat_files*\" | sed -e \"s/[^-][^\\/]*\\// |/g\" -e \"s/|\\([^ ]\\)/|-\\1/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c784e82199239a",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "We load the QPM normalized, real SAR imagery data by calling [`datasets.load_dataset`](https://huggingface.co/docs/datasets/v2.19.0/en/package_reference/loading_methods#datasets.load_dataset) with the [`ImageFolder`](https://huggingface.co/docs/datasets/v2.19.0/en/image_dataset#imagefolder) dataset builder. `ImageFolder` automatically infers the class labels based on the directory names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b9eedb54bff483",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = sample_dir / Path(\"png_images\", \"qpm\", \"real\")\n",
    "raw_dataset = datasets.load_dataset('imagefolder', data_dir=data_dir)\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1cfd9fb801f035",
   "metadata": {},
   "source": [
    "### Verify dataset\n",
    "\n",
    "Check that image labels have been inferred correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef77377f9d52bb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "mstar_labels: list[str] = raw_dataset['train'].features['label'].names\n",
    "mstar_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bb13a6c9f1d2b7",
   "metadata": {},
   "source": [
    "Since the SAR imagery is monochrome, we define a transform to convert the images to RBG format and apply it using the Hugging Face [`map`](https://huggingface.co/docs/datasets/v2.19.0/en/image_process#map) function that applies the transform over an entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637a594d2e28585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(examples):\n",
    "    examples[\"image\"] = [image.convert(\"RGB\") for image in examples[\"image\"]]\n",
    "    return examples\n",
    "\n",
    "raw_dataset = raw_dataset.map(transforms, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fd5520350b9b3b",
   "metadata": {},
   "source": [
    "Display a SAR image annotated with the image format and label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df65e1db98ae6bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mstar_example = raw_dataset['train'][0]\n",
    "\n",
    "display(mstar_example['image'])\n",
    "print(f\"mode {mstar_example['image'].mode}\")\n",
    "print(f\"label {mstar_labels[mstar_example['label']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe3d4da77c5a48e",
   "metadata": {},
   "source": [
    "### Define train, validation and test splits\n",
    "\n",
    "The `datasets.load_dataset` function creates a `train` split by default. By applying the [`datasets.Dataset.train_test_split`](https://huggingface.co/docs/datasets/v2.19.0/en/package_reference/main_classes#datasets.Dataset.train_test_split) method we can partition the dataset defined above into `train`, `valid` and `test` splits that are contained in a [`datasets.DatasetDict`](https://huggingface.co/docs/datasets/v2.19.0/en/package_reference/main_classes#datasets.DatasetDict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0b20dbdabc1491",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = raw_dataset['train'].train_test_split(\n",
    "    test_size=3/10,\n",
    "    stratify_by_column='label'\n",
    ")\n",
    "\n",
    "test_dataset = train_dataset['test'].train_test_split(\n",
    "    test_size=2/3,\n",
    "    stratify_by_column='label'\n",
    ")\n",
    "\n",
    "mstar_dataset = datasets.DatasetDict(\n",
    "    {\n",
    "        'train': train_dataset['train'],\n",
    "        'valid': test_dataset['train'],\n",
    "        'test': test_dataset['test']\n",
    "    }\n",
    ")\n",
    "\n",
    "mstar_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b144cf8be32bda7a",
   "metadata": {},
   "source": [
    "### Dataset statistics\n",
    "\n",
    "Using the Hugging Face [`map`](https://huggingface.co/docs/datasets/v2.19.0/en/image_process#map) function that can apply a transform over an entire dataset, we can produce simple statistics that summarize the data. For example, the `count_labels` function accumulates counts per split of the number of objects of each category that are then used to create a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c1e90c72d364fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_labels(ds: datasets.Dataset) -> list[int]:\n",
    "    ctr: collections.Counter[str] = collections.Counter()\n",
    "    \n",
    "    def inc_label(l: int) -> None:\n",
    "        ctr[mstar_labels[l]] += 1\n",
    "        \n",
    "    ds.map(inc_label, input_columns=['label'])\n",
    "    counts = [ctr[l] for l in mstar_labels]\n",
    "    return counts\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {split: count_labels(mstar_dataset[split]) for split in mstar_dataset.keys()},\n",
    "    index=mstar_labels\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb434b32cab1ad5",
   "metadata": {},
   "source": [
    "A bar chart of the category counts clearly reveals the real MSTAR data is fairly balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af422110da78cf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='bar', \n",
    "        stacked=False, \n",
    "        title='MSTAR Class Counts') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde3d7f3f7f80748",
   "metadata": {},
   "source": [
    "### Saving to Disk or Uploading to S3 Bucket\n",
    "\n",
    "The new MSTAR dataset may be [saved to disk](https://huggingface.co/docs/datasets/v2.19.0/en/package_reference/main_classes#datasets.Dataset.save_to_disk) among other options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e69045cc7bdd81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mstar_path =  Path('mstar_10.hf')    \n",
    "mstar_dataset.save_to_disk(mstar_path)\n",
    "    \n",
    "print(\"Loading the dataset\")\n",
    "print(datasets.load_from_disk(mstar_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18670209a94e8bac",
   "metadata": {},
   "source": [
    "## Integrate into Armory\n",
    "\n",
    "Having imported a SAMPLE subset as a Hugging Face dataset, we are ready to plug our new dataset into the Armory Library framework. This consists of creating an `armory.dataset.ObjectDetectionDataLoader` that defines the underlying [PyTorch dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader). Note that the `armory.data.Scale` object defines the type and scale of the data. The Armory dataloader is then wrapped by an `armory.evaluation.Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a958a898c3e4aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "shuffle = False\n",
    "\n",
    "unnormalized_scale = armory.data.Scale(\n",
    "    dtype=armory.data.DataType.UINT8,\n",
    "    max=255,\n",
    ")\n",
    "\n",
    "mstar_dataloader = armory.dataset.ImageClassificationDataLoader(\n",
    "    mstar_dataset['train'],\n",
    "    dim=armory.data.ImageDimensions.CHW,\n",
    "    scale=unnormalized_scale,\n",
    "    image_key=\"image\",\n",
    "    label_key=\"label\",\n",
    "    batch_size=batch_size,\n",
    "    shuffle=shuffle,\n",
    ")\n",
    "\n",
    "armory_dataset = armory.evaluation.Dataset(\n",
    "    name=\"MSTAR-qpm-real\",\n",
    "    dataloader=mstar_dataloader,\n",
    ")\n",
    "\n",
    "armory_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed3b9c13f56bc79",
   "metadata": {},
   "source": [
    "## Resources\n",
    "- [SAMPLE Public Dataset](https://github.com/benjaminlewis-afrl/SAMPLE_dataset_public)\n",
    "\n",
    "- [Lewis, B., Scarnati, T., Sudkamp, E., Nehrbass, J., Rosencrantz, S., & Zelnio, E. (2019, May). A SAR dataset for ATR development: the Synthetic and Measured Paired Labeled Experiment (SAMPLE). In Algorithms for Synthetic Aperture Radar Imagery XXVI (Vol. 10987, pp. 39-54). SPIE.](https://github.com/benjaminlewis-afrl/SAMPLE_dataset_public/blob/master/sample_public.pdf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "armory-library-venv",
   "language": "python",
   "name": "armory-library-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
